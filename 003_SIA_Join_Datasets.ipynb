{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando o ambiente PySpark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma instância de SparkSession para iniciar uma sessão Spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master('local[*]')\\\n",
    "    .appName('Conversão e manipulação dos arquivos CSV para Parquet')\\\n",
    "    .config('spark.ui.port', '4050')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PYSUS = r'data\\001_PYSUS'\n",
    "PATH_TABNET_UFMUN = r'data\\002_TABNET\\PA_UFMUN.csv'\n",
    "PATH_TABNET_NIVCPL = r'data\\002_TABNET\\PA_NIVCPL.csv'\n",
    "PATH_TABNET_CBOCOD = r'data\\002_TABNET\\PA_CBOCOD.csv'\n",
    "PATH_TABNET_PROC_ID = r'data\\002_TABNET\\PA_PROC_ID.csv'\n",
    "PATH_TABNET_G_PROC_ID = r'data\\002_TABNET\\PA_G_PROC_ID.csv'\n",
    "PATH_TABNET_SG_PROC_ID = r'data\\002_TABNET\\PA_SG_PROC_ID.csv'\n",
    "\n",
    "PATH_PYSUS_PARQUET = r'data\\003_JOIN_DATASETS\\PYSUS_PARQUET'\n",
    "PATH_FINAL_DATASET = r'data\\003_JOIN_DATASETS\\FINAL_DATASET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando DataFrame Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    return spark.read.csv(path, sep=';', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PA_UFMUN: integer (nullable = true)\n",
      " |-- PA_CMP: string (nullable = true)\n",
      " |-- PA_PROC_ID: integer (nullable = true)\n",
      " |-- PA_NIVCPL: integer (nullable = true)\n",
      " |-- PA_CBOCOD: string (nullable = true)\n",
      " |-- PA_OBITO: integer (nullable = true)\n",
      " |-- PA_ENCERR: integer (nullable = true)\n",
      " |-- PA_PERMAN: integer (nullable = true)\n",
      " |-- PA_ALTA: integer (nullable = true)\n",
      " |-- PA_TRANSF: integer (nullable = true)\n",
      " |-- PA_QTDAPR: integer (nullable = true)\n",
      " |-- PA_VALAPR: double (nullable = true)\n",
      " |-- PA_UFDIF: integer (nullable = true)\n",
      " |-- PA_MNDIF: integer (nullable = true)\n",
      " |-- PA_G_PROC_ID: integer (nullable = true)\n",
      " |-- PA_SG_PROC_ID: integer (nullable = true)\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_pysus = read_csv(PATH_PYSUS)\n",
    "df_pysus.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PA_UFMUN: integer (nullable = true)\n",
      " |-- DS_PA_UFMUN: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ufmun = read_csv(PATH_TABNET_UFMUN)\n",
    "df_ufmun.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PA_NIVCPL: integer (nullable = true)\n",
      " |-- DS_PA_NIVCPL: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_nivcpl = read_csv(PATH_TABNET_NIVCPL)\n",
    "df_nivcpl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PA_CBOCOD: string (nullable = true)\n",
      " |-- DS_PA_CBOCOD: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cbocod = read_csv(PATH_TABNET_CBOCOD)\n",
    "df_cbocod.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PA_PROC_ID: integer (nullable = true)\n",
      " |-- DS_PA_PROC_ID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_proc_id = read_csv(PATH_TABNET_PROC_ID)\n",
    "df_proc_id.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PA_G_PROC_ID: integer (nullable = true)\n",
      " |-- DS_PA_G_PROC_ID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_g_proc_id = read_csv(PATH_TABNET_G_PROC_ID)\n",
    "df_g_proc_id.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PA_SG_PROC_ID: integer (nullable = true)\n",
      " |-- DS_PA_SG_PROC_ID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sg_proc_id = read_csv(PATH_TABNET_SG_PROC_ID)\n",
    "df_sg_proc_id.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertendo base do PySUS de CSV para PARQUET para obter melhor desempenho de manipulação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 'partitionBy' especifica a coluna pela qual os dados serão particionados. Neste caso, os dados serão particionados pela coluna de data 'PA_CMP'\n",
    "df_pysus.write.parquet(\n",
    "        path=PATH_PYSUS_PARQUET,\n",
    "        mode='overwrite',\n",
    "        partitionBy='PA_CMP' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PA_UFMUN: integer (nullable = true)\n",
      " |-- PA_PROC_ID: integer (nullable = true)\n",
      " |-- PA_NIVCPL: integer (nullable = true)\n",
      " |-- PA_CBOCOD: string (nullable = true)\n",
      " |-- PA_OBITO: integer (nullable = true)\n",
      " |-- PA_ENCERR: integer (nullable = true)\n",
      " |-- PA_PERMAN: integer (nullable = true)\n",
      " |-- PA_ALTA: integer (nullable = true)\n",
      " |-- PA_TRANSF: integer (nullable = true)\n",
      " |-- PA_QTDAPR: integer (nullable = true)\n",
      " |-- PA_VALAPR: double (nullable = true)\n",
      " |-- PA_UFDIF: integer (nullable = true)\n",
      " |-- PA_MNDIF: integer (nullable = true)\n",
      " |-- PA_G_PROC_ID: integer (nullable = true)\n",
      " |-- PA_SG_PROC_ID: integer (nullable = true)\n",
      " |-- PA_CMP: date (nullable = true)\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_pysus = spark.read.parquet(PATH_PYSUS_PARQUET)\n",
    "df_pysus.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O dataset possui 33831473 linhas.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'O dataset possui {df_pysus.count()} linhas.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntando todos os DataFrames\n",
    "O objetivo é adicionar as colunas de descrição obtidos no TabNet para enriquecer o dataset extraído da biblioteca PySUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------+---------+\n",
      "|PA_UFMUN|DS_PA_UFMUN|PA_QTDAPR|PA_VALAPR|\n",
      "+--------+-----------+---------+---------+\n",
      "|261160  |RECIFE     |1        |1.85     |\n",
      "|260680  |IGARASSU   |1        |0.0      |\n",
      "|261160  |RECIFE     |2        |3.7      |\n",
      "+--------+-----------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_pysus.join(df_ufmun, 'PA_UFMUN', how='left')\n",
    "df.select('PA_UFMUN', 'DS_PA_UFMUN', 'PA_QTDAPR', 'PA_VALAPR')\\\n",
    "  .show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+---------+---------+\n",
      "|PA_NIVCPL|DS_PA_NIVCPL      |PA_QTDAPR|PA_VALAPR|\n",
      "+---------+------------------+---------+---------+\n",
      "|2        |Média Complexidade|1        |1.85     |\n",
      "|2        |Média Complexidade|1        |0.0      |\n",
      "|2        |Média Complexidade|2        |3.7      |\n",
      "+---------+------------------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.join(df_nivcpl, 'PA_NIVCPL', how='left')\n",
    "df.select('PA_NIVCPL', 'DS_PA_NIVCPL', 'PA_QTDAPR', 'PA_VALAPR')\\\n",
    "  .show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------------------+---------+---------+\n",
      "|PA_CBOCOD|DS_PA_CBOCOD                   |PA_QTDAPR|PA_VALAPR|\n",
      "+---------+-------------------------------+---------+---------+\n",
      "|225250   |Medico ginecologista e obstetra|1        |1.85     |\n",
      "|251510   |Psicologo clinico              |1        |0.0      |\n",
      "|225250   |Medico ginecologista e obstetra|2        |3.7      |\n",
      "+---------+-------------------------------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.join(df_cbocod, 'PA_CBOCOD', how='left')\n",
    "df.select('PA_CBOCOD', 'DS_PA_CBOCOD', 'PA_QTDAPR', 'PA_VALAPR')\\\n",
    "  .show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------------------+---------+---------+\n",
      "|PA_PROC_ID|DS_PA_PROC_ID                            |PA_QTDAPR|PA_VALAPR|\n",
      "+----------+-----------------------------------------+---------+---------+\n",
      "|202010317 |DOSAGEM DE CREATININA                    |1        |1.85     |\n",
      "|301080356 |PROMOCAO DE CONTRATUALIDADE NO TERRITORIO|1        |0.0      |\n",
      "|202010317 |DOSAGEM DE CREATININA                    |2        |3.7      |\n",
      "+----------+-----------------------------------------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.join(df_proc_id, 'PA_PROC_ID', how='left')\n",
    "df.select('PA_PROC_ID', 'DS_PA_PROC_ID', 'PA_QTDAPR', 'PA_VALAPR')\\\n",
    "  .show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------------------------+---------+---------+\n",
      "|PA_G_PROC_ID|DS_PA_G_PROC_ID                         |PA_QTDAPR|PA_VALAPR|\n",
      "+------------+----------------------------------------+---------+---------+\n",
      "|2           |Procedimentos com finalidade diagnóstica|1        |1.85     |\n",
      "|3           |Procedimentos clínicos                  |1        |0.0      |\n",
      "|2           |Procedimentos com finalidade diagnóstica|2        |3.7      |\n",
      "+------------+----------------------------------------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.join(df_g_proc_id, 'PA_G_PROC_ID', how='left')\n",
    "df.select('PA_G_PROC_ID', 'DS_PA_G_PROC_ID', 'PA_QTDAPR', 'PA_VALAPR')\\\n",
    "  .show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------------------------------+---------+---------+\n",
      "|PA_SG_PROC_ID|DS_PA_SG_PROC_ID                          |PA_QTDAPR|PA_VALAPR|\n",
      "+-------------+------------------------------------------+---------+---------+\n",
      "|202          |Diagnóstico em laboratório clínico        |1        |1.85     |\n",
      "|301          |Consultas / Atendimentos / Acompanhamentos|1        |0.0      |\n",
      "|202          |Diagnóstico em laboratório clínico        |2        |3.7      |\n",
      "+-------------+------------------------------------------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.join(df_sg_proc_id, 'PA_SG_PROC_ID', how='left')\n",
    "df.select('PA_SG_PROC_ID', 'DS_PA_SG_PROC_ID', 'PA_QTDAPR', 'PA_VALAPR')\\\n",
    "  .show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Versão final do Dataset\n",
    "df.write.parquet(\n",
    "        path=PATH_FINAL_DATASET,\n",
    "        mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
